{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and append information to respective dictionaries\n",
    "with open('combined_data_1.txt', 'r') as inFile:\n",
    "    curMovie = 0\n",
    "    for line in inFile.readlines():\n",
    "        if len(line.split(\":\")) == 2:\n",
    "            curMovie = int(line.strip(':\\n'))\n",
    "        else:\n",
    "            splitLine = line.split(\",\")\n",
    "            lineVals = [int(splitLine[0].strip()), int(splitLine[1].strip())]\n",
    "            movieDict['movieId'].append(curMovie)\n",
    "            movieDict['userId'].append(lineVals[0])\n",
    "            movieDict['rating'].append(lineVals[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe for movieSet\n",
    "movieFrame = pd.DataFrame(movieDict)\n",
    "del movieDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD, SVDpp\n",
    "from surprise.prediction_algorithms import BaselineOnly\n",
    "from surprise.model_selection import train_test_split, KFold\n",
    "import surprise.accuracy as accuracy\n",
    "import time\n",
    "\n",
    "# Gaurantees all folds are equivalent\n",
    "kf = KFold(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import into new loc in scikit\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(movieFrame[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "_, testing = train_test_split(data, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9000  0.9000  0.9007  0.9005  0.9008  0.9004  0.0003  \n",
      "Fit time          930.54  965.23  948.88  956.08  945.77  949.30  11.53   \n",
      "Test time         69.06   60.97   73.53   56.09   65.58   65.05   6.09    \n",
      "Time Elapsed [SVD]: 5313.096236944199\n"
     ]
    }
   ],
   "source": [
    "# SVD algorithm\n",
    "algoSVD = SVD()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resSVD = cross_validate(algoSVD, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SVD]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD++ would generally perform the best, but with a settling time of 2 hours for 1M entries, it's realistically impossible to run this on even one part of the Neflix data so that it can be ran multiple times within the span of the project. Therefore, we test it only on 10% of the data and evaluate it on the same 30% used for the other sets. We should be careful to compare the performance to other values because even though the solution space is the same, performance obviously takes a hit as not much data is there to support it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Time Elapsed [SVD++]: 549.9810678958893\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVD++ is MUCH more computationally intensive than the biased SVD\n",
    "    implementation and scales up on the order of >O(N^3)! As a result,\n",
    "    we only take 10% of our dataset in order to meet the constraints\n",
    "    of the project. (Runtime generally is around 2 HRS FOR 1MIL ENTRIES!)\n",
    "    Not possible within time constraint!!!\"\"\"\n",
    "#split [Yes this is very little, but it's mostly done as an example]\n",
    "trainingSVDpp, _ = train_test_split(data, test_size=.90)\n",
    "\n",
    "# SVD++ algorithm\n",
    "algo2 = SVDpp(verbose=True)\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resSVDpp = algo2.fit(trainingSVDpp)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SVD++]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9329  0.9330  0.9324  0.9325  0.9333  0.9328  0.0003  \n",
      "Fit time          92.88   102.66  103.08  101.77  106.83  101.44  4.62    \n",
      "Test time         60.14   58.09   59.15   59.09   52.84   57.86   2.59    \n",
      "Time Elapsed [Baseline]: 1044.3228101730347\n"
     ]
    }
   ],
   "source": [
    "# baseline algorithm\n",
    "algo3 = BaselineOnly()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resBASE = cross_validate(algo3, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [Baseline]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7888\n",
      "RMSE: 0.9382\n",
      "RMSE: 0.9222\n"
     ]
    }
   ],
   "source": [
    "# compute RMSE using any algorithm on testing dataset\n",
    "predictions = algoSVD.test(testing)\n",
    "SVDacc = accuracy.rmse(predictions)\n",
    "predictions = algo2.test(testing)\n",
    "SVDppacc = accuracy.rmse(predictions)\n",
    "predictions = algo3.test(testing)\n",
    "BASEacc = accuracy.rmse(predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SlopeOne on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9307  0.9309  0.9310  0.9309  0.9300  0.9307  0.0003  \n",
      "Fit time          132.39  136.86  131.75  138.27  126.13  133.08  4.28    \n",
      "Test time         494.14  480.06  483.93  467.03  465.15  478.06  10.82   \n",
      "Time Elapsed [SlopeOne]: 3294.1948626041412\n"
     ]
    }
   ],
   "source": [
    "from surprise.prediction_algorithms import SlopeOne\n",
    "\n",
    "# slope one algorithm\n",
    "algoSO = SlopeOne()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resKNN = cross_validate(algoKNN, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SlopeOne]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9074\n"
     ]
    }
   ],
   "source": [
    "predictions = algoSO.test(testing)\n",
    "SOacc = accuracy.rmse(predictions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point, we just try evaluating everything on a tiny subset given that a naive algorithm like KNN would obviously generate a similarity matrix far too large to store with more than 50k users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the first 10 movies, there are 19519 unique users and 20352 entries\n"
     ]
    }
   ],
   "source": [
    "movieMaxCount = 10\n",
    "print(\"In the first {} movies, there are {} unique users and {} entries\".format(movieMaxCount,\n",
    "        len(movieFrame[movieFrame['movieId'] <= movieMaxCount].userId.unique()), \n",
    "        movieFrame[movieFrame['movieId'] <= movieMaxCount].shape[0]))\n",
    "newDataSet = movieFrame[movieFrame['movieId'] <= movieMaxCount]\n",
    "\n",
    "# Now proceed to perform predictions based on smaller dataset\n",
    "dataSmall = Dataset.load_from_df(newDataSet[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2747  1.3056  1.2968  1.3010  1.2908  1.2938  0.0107  \n",
      "Fit time          17.08   17.59   17.94   17.87   17.11   17.52   0.36    \n",
      "Test time         0.40    0.45    0.39    0.51    0.40    0.43    0.04    \n",
      "Time Elapsed [KNN-Pearson-NoBaseLine]: 89.82383394241333\n"
     ]
    }
   ],
   "source": [
    "# similarity algorithm\n",
    "sim_options = {'name': 'pearson_baseline', 'shrinkage': 0}  # shrinkage=0 => no using baseline means to improve acc\n",
    "algoKNNSmall = KNNBasic(sim_options=sim_options, verbose = True)\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resKNN = cross_validate(algoKNN, dataSmall, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [KNN-Pearson-NoBaseLine]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we measure the results compared to the other algorithms as well. This time it's comparable as all will be using the same small dataset with cross-validation present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2801  1.2721  1.2827  1.2656  1.2508  1.2703  0.0114  \n",
      "Fit time          0.74    0.74    0.74    0.75    0.74    0.74    0.01    \n",
      "Test time         0.02    0.02    0.02    0.02    0.02    0.02    0.00    \n",
      "Time Elapsed [SVD]: 3.8925845623016357\n"
     ]
    }
   ],
   "source": [
    "# SVD algorithm\n",
    "algoSVDsm = SVD()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resSVDsm = cross_validate(algoSVDsm, dataSmall, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SVD]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.3198  1.2757  1.3125  1.2896  1.2851  1.2966  0.0168  \n",
      "Fit time          1.17    1.20    1.20    1.17    1.17    1.18    0.02    \n",
      "Test time         0.02    0.02    0.02    0.02    0.02    0.02    0.00    \n",
      "Time Elapsed [SVD++]: 6.113745450973511\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVD++ is MUCH more computationally intensive than the biased SVD\n",
    "    implementation and scales up on the order of >O(N^3)! As a result,\n",
    "    we only take 10% of our dataset in order to meet the constraints\n",
    "    of the project. (Runtime generally is around 2 HRS FOR 1MIL ENTRIES!)\n",
    "    Not possible within time constraint!!!\"\"\"\n",
    "# SVD++ algorithm\n",
    "algo2sm = SVDpp()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resSVDppsm = cross_validate(algo2sm, dataSmall, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SVD++]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SlopeOne on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.3116  1.3011  1.3100  1.3107  1.3022  1.3071  0.0045  \n",
      "Fit time          0.10    0.09    0.10    0.10    0.10    0.10    0.00    \n",
      "Test time         0.02    0.02    0.02    0.02    0.02    0.02    0.00    \n",
      "Time Elapsed [SlopeOne]: 5.866800785064697\n"
     ]
    }
   ],
   "source": [
    "from surprise.prediction_algorithms import SlopeOne\n",
    "\n",
    "# slope one algorithm\n",
    "algoSOsm = SlopeOne()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resSOsm = cross_validate(algoSOsm, dataSmall, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SlopeOne]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2740  1.2600  1.2795  1.2733  1.2602  1.2694  0.0079  \n",
      "Fit time          0.04    0.04    0.04    0.04    0.05    0.04    0.01    \n",
      "Test time         0.01    0.01    0.02    0.01    0.02    0.02    0.00    \n",
      "Time Elapsed [Baseline]: 0.3749959468841553\n"
     ]
    }
   ],
   "source": [
    "# baseline algorithm\n",
    "algo3sm = BaselineOnly()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resBASEsm = cross_validate(algo3sm, dataSmall, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [Baseline]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in movie data into a dict\n",
    "movieInfo = {'movieId':[], 'movieYr':[], 'movieNm':[]}\n",
    "with open('netflixdata\\movie_titles.csv', 'r') as movieInd:\n",
    "    for line in movieInd.readlines():\n",
    "        curLine = line.split(',')\n",
    "        if(curLine[1].strip()=='NULL'):\n",
    "            continue\n",
    "        formattedLine = [int(curLine[0].strip()), int(curLine[1].strip()), curLine[2].strip()]\n",
    "        movieInfo['movieId'].append(formattedLine[0])\n",
    "        movieInfo['movieYr'].append(formattedLine[1])\n",
    "        movieInfo['movieNm'].append(formattedLine[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe for movieInfo\n",
    "infoFrame = pd.DataFrame(movieInfo)\n",
    "del movieInfo\n",
    "joinedFrame = movieFrame.merge(infoFrame, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of ratings per movie each year\n",
    "years = list(joinedFrame['movieYr'].value_counts())[::-1]\n",
    "numMovies = list(joinedFrame.groupby('movieYr')['movieId'].nunique())\n",
    "normalized = []\n",
    "for i in range(len(years)):\n",
    "    normalized.append(years[i]/numMovies[i])\n",
    "mean = np.mean(normalized)\n",
    "std = np.std(normalized)\n",
    "new_normalized = [x for x in normalized if (x < mean + 3 * std)]\n",
    "x_axis = list(joinedFrame['movieYr'].unique()[::-1])\n",
    "x_axis.pop()\n",
    "plt.scatter(x_axis, new_normalized)\n",
    "plt.plot(np.unique(x_axis), np.poly1d(np.polyfit(x_axis, new_normalized, 1))(np.unique(x_axis)),color='r')\n",
    "plt.ylabel(\"Number of ratings submitted per movie\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.title(\"Scatter plot of the number of ratings per movie in each movie production year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average rating of all movies throughout the years\n",
    "x = joinedFrame.groupby('movieYr').mean().reset_index()['movieYr']\n",
    "y = joinedFrame.groupby('movieYr').mean().reset_index()['rating']\n",
    "plt.scatter(x,y)\n",
    "plt.ylabel(\"Average Rating\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.title(\"Scatter plot of the average movie rating versus movie production year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of ratings users submit\n",
    "values = list(joinedFrame['userId'].value_counts())\n",
    "std = np.std(values)\n",
    "mean = np.mean(values)\n",
    "new_values = [x for x in values if (x < mean + 3 * std)]\n",
    "plt.hist(new_values,bins=50)\n",
    "plt.ylabel(\"Number of users\")\n",
    "plt.xlabel(\"Number of ratings submitted\")\n",
    "plt.title(\"Scatter plot of the number of ratings per user submits\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of movies listed on Netflix each year\n",
    "plt.scatter(joinedFrame['movieYr'].unique()[::-1],\n",
    "            joinedFrame.groupby('movieYr')['movieId'].nunique())\n",
    "plt.ylabel(\"Number of movies\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.title(\"Scatter plot of the number of movies in catalog for each production year\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
